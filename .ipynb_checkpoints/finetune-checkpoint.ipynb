{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901c9ae3",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb82de",
   "metadata": {},
   "source": [
    "## Scitail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f2243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': 'Pluto rotates once on its axis every 6.39 Earth days;', 'hypothesis': 'Earth rotates on its axis once times in one day.', 'label': 'neutral'}\n",
      "{'premise': 'An introduction to atoms and elements, compounds, atomic structure and bonding, the molecule and chemical reactions.', 'hypothesis': 'Replace another in a molecule happens to atoms during a substitution reaction.', 'label': 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SciTail dataset\n",
    "scitail_dataset = load_dataset(\"scitail\", \"tsv_format\")\n",
    "\n",
    "# Accessing the train and validation sets\n",
    "train_set = scitail_dataset['train']\n",
    "validation_set = scitail_dataset['validation']\n",
    "\n",
    "# Print some examples to see the data\n",
    "print(train_set[0])\n",
    "print(validation_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ddaa8",
   "metadata": {},
   "source": [
    "## ARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4919d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n",
      "1172\n",
      "{'id': 'Mercury_SC_415702', 'question': 'George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most heat?', 'choices': {'text': ['dry palms', 'wet palms', 'palms covered with oil', 'palms covered with lotion'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'A'}\n",
      "{'id': 'Mercury_SC_407695', 'question': 'Juan and LaKeisha roll a few objects down a ramp. They want to see which object rolls the farthest. What should they do so they can repeat their investigation?', 'choices': {'text': ['Put the objects in groups.', 'Change the height of the ramp.', 'Choose different objects to roll.', 'Record the details of the investigation.'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'D'}\n",
      "{'id': 'Mercury_7175875', 'question': 'An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?', 'choices': {'text': ['Planetary density will decrease.', 'Planetary years will become longer.', 'Planetary days will become shorter.', 'Planetary gravity will become stronger.'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'C'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the ARC dataset\n",
    "arc_dataset = load_dataset(\"ai2_arc\", \"ARC-Challenge\")\n",
    "\n",
    "# Accessing the different splits\n",
    "train_set = arc_dataset['train']\n",
    "validation_set = arc_dataset['validation']\n",
    "test_set = arc_dataset['test']\n",
    "\n",
    "print(len(arc_dataset['train']))\n",
    "print(len(arc_dataset['test']))\n",
    "\n",
    "# Print some examples to see the data\n",
    "print(train_set[0])\n",
    "print(validation_set[0])\n",
    "print(test_set[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02798b42",
   "metadata": {},
   "source": [
    "### Convert to ChatGPT style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b9aa55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most heat?\n",
      "A) dry palms\n",
      "B) wet palms\n",
      "C) palms covered with oil\n",
      "D) palms covered with lotion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_arc_data(item):\n",
    "    # Formatting the question\n",
    "    question = f\"Q: {item['question']}\\n\"\n",
    "    \n",
    "    # Formatting each choice\n",
    "    choices = ''\n",
    "    for idx, choice in enumerate(item['choices']['text']):\n",
    "        choices += f\"{chr(65 + idx)}) {choice}\\n\"\n",
    "    \n",
    "    # Combine question and choices\n",
    "    return question + choices\n",
    "\n",
    "# Example usage\n",
    "formatted_example = format_arc_data(arc_dataset['train'][0])\n",
    "print(formatted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eabb87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../finetune_config.json\") as file:\n",
    "    conf = json.load(file)\n",
    "\n",
    "#conf['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be850be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai\n",
      "  Downloading openai-1.25.2-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Downloading openai-1.25.2-py3-none-any.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m283.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m282.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: httpcore, httpx, openai\n",
      "Successfully installed httpcore-1.0.5 httpx-0.27.0 openai-1.25.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621a859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=conf[\"OPENAI_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e3f28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B) wet palms\\n\\nWet skin conducts heat better than dry skin, so rubbing wet palms together will produce the most heat. The water acts as a conductor and helps transfer the heat more efficiently from friction.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    return chat_completion\n",
    "\n",
    "chat_completion = chat(formatted_example)\n",
    "response_message = chat_completion.choices[0].message.content\n",
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c938fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a30dc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The correct answer is A) dry palms.\\n\\nWhen George rubs his hands together, the friction between his palms generates heat. The amount of heat generated depends on the coefficient of friction between the two surfaces in contact. In this case, the coefficient of friction is highest when the palms are dry, which means that the surfaces are in close contact and can generate the most heat.\\n\\nWhen the palms are wet (option B), the water reduces the coefficient of friction, making it more difficult to generate heat. Similarly, when the palms are covered with oil or lotion (options C and D), these substances reduce the friction between the palms, making it harder to generate heat.\\n\\nTherefore, rubbing dry palms together will produce the most heat.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "    api_key = conf[\"NVIDIA_API_KEY\"]\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"meta/llama3-70b-instruct\",\n",
    "    messages=[{\"role\":\"user\",\"content\":formatted_example}],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    #stream=True\n",
    ")\n",
    "\n",
    "# for chunk in completion:\n",
    "#     if chunk.choices[0].delta.content is not None:\n",
    "#         print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n",
    "chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3339f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
