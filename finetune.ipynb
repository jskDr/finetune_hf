{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13e81ca",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ea738",
   "metadata": {},
   "source": [
    "## Scitail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7d29db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading readme: 100%|██████████| 10.1k/10.1k [00:00<00:00, 36.6MB/s]\n",
      "Downloading data: 100%|██████████| 1.57M/1.57M [00:01<00:00, 1.51MB/s]\n",
      "Downloading data: 100%|██████████| 162k/162k [00:00<00:00, 219kB/s]\n",
      "Downloading data: 100%|██████████| 99.8k/99.8k [00:00<00:00, 150kB/s]\n",
      "Generating train split: 100%|██████████| 23097/23097 [00:00<00:00, 744551.58 examples/s]\n",
      "Generating test split: 100%|██████████| 2126/2126 [00:00<00:00, 588237.37 examples/s]\n",
      "Generating validation split: 100%|██████████| 1304/1304 [00:00<00:00, 501317.36 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'premise': 'Pluto rotates once on its axis every 6.39 Earth days;', 'hypothesis': 'Earth rotates on its axis once times in one day.', 'label': 'neutral'}\n",
      "{'premise': 'An introduction to atoms and elements, compounds, atomic structure and bonding, the molecule and chemical reactions.', 'hypothesis': 'Replace another in a molecule happens to atoms during a substitution reaction.', 'label': 'neutral'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SciTail dataset\n",
    "scitail_dataset = load_dataset(\"scitail\", \"tsv_format\")\n",
    "\n",
    "# Accessing the train and validation sets\n",
    "train_set = scitail_dataset['train']\n",
    "validation_set = scitail_dataset['validation']\n",
    "\n",
    "# Print some examples to see the data\n",
    "print(train_set[0])\n",
    "print(validation_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ee8ff5",
   "metadata": {},
   "source": [
    "## ARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1b275de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119\n",
      "1172\n",
      "{'id': 'Mercury_SC_415702', 'question': 'George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most heat?', 'choices': {'text': ['dry palms', 'wet palms', 'palms covered with oil', 'palms covered with lotion'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'A'}\n",
      "{'id': 'Mercury_SC_407695', 'question': 'Juan and LaKeisha roll a few objects down a ramp. They want to see which object rolls the farthest. What should they do so they can repeat their investigation?', 'choices': {'text': ['Put the objects in groups.', 'Change the height of the ramp.', 'Choose different objects to roll.', 'Record the details of the investigation.'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'D'}\n",
      "{'id': 'Mercury_7175875', 'question': 'An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?', 'choices': {'text': ['Planetary density will decrease.', 'Planetary years will become longer.', 'Planetary days will become shorter.', 'Planetary gravity will become stronger.'], 'label': ['A', 'B', 'C', 'D']}, 'answerKey': 'C'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the ARC dataset\n",
    "arc_dataset = load_dataset(\"ai2_arc\", \"ARC-Challenge\")\n",
    "\n",
    "# Accessing the different splits\n",
    "train_set = arc_dataset['train']\n",
    "validation_set = arc_dataset['validation']\n",
    "test_set = arc_dataset['test']\n",
    "\n",
    "print(len(arc_dataset['train']))\n",
    "print(len(arc_dataset['test']))\n",
    "\n",
    "# Print some examples to see the data\n",
    "print(train_set[0])\n",
    "print(validation_set[0])\n",
    "print(test_set[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac754d4",
   "metadata": {},
   "source": [
    "### Convert to ChatGPT style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab12e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: George wants to warm his hands quickly by rubbing them. Which skin surface will produce the most heat?\n",
      "A) dry palms\n",
      "B) wet palms\n",
      "C) palms covered with oil\n",
      "D) palms covered with lotion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def format_arc_data(item):\n",
    "    # Formatting the question\n",
    "    question = f\"Q: {item['question']}\\n\"\n",
    "    \n",
    "    # Formatting each choice\n",
    "    choices = ''\n",
    "    for idx, choice in enumerate(item['choices']['text']):\n",
    "        choices += f\"{chr(65 + idx)}) {choice}\\n\"\n",
    "    \n",
    "    # Combine question and choices\n",
    "    return question + choices\n",
    "\n",
    "# Example usage\n",
    "formatted_example = format_arc_data(arc_dataset['train'][0])\n",
    "print(formatted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e6822a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../finetune_config.json\") as file:\n",
    "    conf = json.load(file)\n",
    "\n",
    "#conf['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c48d44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai\n",
      "  Downloading openai-1.25.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m294.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m281.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: httpcore, httpx, openai\n",
      "Successfully installed httpcore-1.0.5 httpx-0.27.0 openai-1.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94847fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B) wet palms\\n\\nWet palms will produce the most heat because the water on the surface of the skin evaporates and takes away heat from the skin, making it feel colder. When George rubs his wet hands together, the friction will generate heat more quickly than if his palms were dry, covered with oil, or lotion.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=conf[\"OPENAI_API_KEY\"],\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "chat_completion\n",
    "response_message = chat_completion.choices[0].message.content\n",
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff1b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
